\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Anh)}{Supervised learning models}{1}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{could be}{1}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{, as known as dataset drift}{1}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{, potentially rendering}{1}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{, as known as concept drift}{1}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Anh)}{concept drift}{1}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{supervised learning}{1}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Anh)}{a powerful statistical process control (SPC) technique, multivariate EWMA chart}{1}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{in Phase-I and Phase-II respectively}{1}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{the diagnosis method proposed can}{1}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{This is the first time in the concept drift literatures that a score-based method is developed.}{1}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{any parametric supervised learning}{1}}
\citation{fong2015change}
\citation{im2012time}
\citation{carmona2010gnusmail}
\citation{koren2009collaborative}
\citation{bui2018monitoring}
\citation{vzliobaite2016overview}
\citation{moreno2012unifying}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{as shown in experiments with various models on simulated and real datasets.}{2}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{The impressive performance of early detection and interpretability demonstrate the superiority of the proposed method over current popular ones.}{2}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{We also discuss some related results from econometric literatures and draw a connection between our and their methods.}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Anh)}{stationary}{2}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Anh)}{, where the stationarity refers to the conditional distribution, $P(Y|\bm  {X})$}{2}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Anh)}{Concept drift}{2}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{The change in $P (Y|\bm  {X}, \bm  { \theta })$ can happen in training and serving models.}{2}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{potentially rule out}{2}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{as much as possible, through so-called retrospective analysis}{2}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{or diagnose}{2}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{The case with scale response can}{2}}
\citation{wang2003mining}
\citation{calandra2012learning}
\citation{dos2016fast}
\citation{frias2015online}
\citation{barros2018large}
\citation{ross2012exponentially}
\citation{gonccalves2014comparative}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Concept drift is fairly common in practical applications. For example, in spam filtering, machine learning models can use features like words, spelling, and addresses to determine whether an email comes from a suspicious source. However, when spammers find their outgoing emails are blocked, they can invent new templates of emails trying to bypass the spam checking. Or some emails previously not regarded as spams become ones after a while. These phenomena in one case can originate from hidden effects or contexts not captured by machine learning models. When hidden effects don't change, the current model can approximate relationship between covariates and responses, if well-trained and validated. However, after the context drifts, the same model may have very poor predictability based on input variables. Battling against performance degradation resulting from concept drift is especially important in streaming data setting. Considering large amount of data and big scale of models, a good method for solving concept drift problems should be able to handle different kinds of drifts very fast without requiring too many data points. Also, to quickly pinpoint specific features or covariates contributing to a drift, a good method should also provide interpretive guidance.}{3}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{The concept drift problem have emerged in different fields, including machine learning\nobreakspace  {}(cite{gama2004learning}), statistics\nobreakspace  {}(cite{brown1975techniques}), and econometrics\nobreakspace  {}(cite{kuan1995generalized}). Classification problems are especially interested in by machine learning communities.}{3}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{In fields of statistics and econometrics, score-based testing methods\nobreakspace  {}(cite{zeileis2005unified}) are developed for both regression and classification problems to handle changes of parameters, where the score function is defined as gradient of cost function (e.g., negative log-likelihood) of single observation.}{3}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{In this paper, we will discuss the limitation of using error-based methods, like missing potential concept drifts and opportunities of improving models (as illustrated in Figure\nobreakspace  {}\ref  {fig:logi_err_rate_unch}) and so on. To overcome those problems, we choose to monitor stochastic score function, defined as the gradient of log-likelihood.}{3}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{and quantitative}{3}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{across the fields}{3}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{and diagnose}{3}}
\citation{montgomery2007introduction}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{In this study, we develop a method of detecting concept drift .}{4}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{monitors}{4}}
\pgfsyspdfmark {pgfid1}{7988500}{27203836}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{descent (SGD)}{4}}
\pgfsyspdfmark {pgfid2}{2917763}{27217292}
\pgfsyspdfmark {pgfid3}{5232228}{26972106}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{can detect the change of vectors in a direction invariant manner and the exponentially decayed weights smoothly distributed higher weights on recent data samples over earlier ones without relying too much on a single data point. The value of decaying parameters depends on specific applications and a good choice can find balance between false-alarm rate and detection speed.}{4}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{error-based}{4}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{for parametric models}{4}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{the gradient of log-likelihood as a function}{4}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{Besides interests from mathematical perspective, concept drift is fairly common in practical applications. For example, in spam filtering, machine learning models can use features like words, spelling, and addresses to determine whether an email comes from a suspicious source. However, when spammers find their outgoing emails are blocked, they can invent new templates of emails trying to bypass the spam checking. Or some emails previously not regarded as spams become ones after a while. Another example is predicting efficacy of antibiotics using predictive models. With more usage of a certain antibiotics, bacterias become more resistant offsetting the efficacy, up to a point when it becomes virtually useless. In other cases, it can also be captured by some context variables which, instead of being explicitly used as covariates in training, are converted to weights to select historical data having similar context for training\nobreakspace  {}(cite{barakat2018context}). The main difference in the two settings is that the former assumes no explicit knowledge in concept drift, while in the later case concept drifts are identified given candidate context variables. We clarify that this paper focuses on the former setting, which no prior knowledge of concept drift is required. These phenomena in one case can originate from hidden effects or contexts not captured by machine learning models. When hidden effects don't change, the current model can approximate relationship between covariates and responses as well as the one being trained. However, after the context drifts, the same model may have very poor predictability based on input variables. Battling against performance degradation resulting from concept drift is especially important in streaming data setting. Considering large amount of data and big scale of models, a good method for solving concept drift problems should be able to handle different kinds of drift very fast without requiring too many data points. Also, to quickly pinpoint specific features or covariates contributing to a drift, a good method should also provide interpretive guidance.}{5}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{through retrospective analysis}{5}}
\citation{moreno2012unifying}
\citation{zeileis2005unified}
\citation{zeileis2007generalized}
\citation{xia2009monitoring}
\citation{ross2012exponentially}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Simulated datasets are also used to illustrate the advantages of score-based over error-based methods, in terms of detection speed and interpretability, under circumstances of abrupt/gradual concept drifts and with/without multi-colinearity. Overall, we show that monitoring score instead of error would give overall better performance and understanding in handling concept drift with very little extra cost.}{6}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{Four parametric models, linear, logistic, multinomial, and Poisson regression, are used as examples to investigate this method. For non-parametric or semi-parametric model, we investigate multi-layer perceptron (MLP) as an example. The MEWMA can be used to track overall concept drift with special treatment to handle models with a large amount of parameters, like MLP. For linear and mildly nonlinear models, it can also track concept drift of individual covariates. Simulated datasets are carefully designed to demonstrate that, for linear models, component-wise concept drift can be completely recovered even with multi-collinearity; for nonlinear models like logistic regression, our method can still be practically useful because, when concept drift happens and a model being trained is mostly affected (will be clarified later), we can linearize the decoupling matrix to get a good approximation and obtain decoupled concept drifts for covariates. {Furthermore, other methods monitoring EWMA of prediction residual or error rate are compared with our method showing that monitoring the score function can provide earlier detection.} Experimental studies on real datasets of credit risk and bike sharing prove that tracking sample score vectors is better than simply monitoring prediction error or residual and offers more interpretive results for improving performance of predictive models.}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Works}{6}{section.2}\protected@file@percent }
\citation{tsymbal2004problem}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{in econometrics literatures}{7}}
\pgfsyspdfmark {pgfid6}{25759643}{39146149}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{can achieve earlier detection and}{7}}
\pgfsyspdfmark {pgfid9}{37307902}{39159605}
\pgfsyspdfmark {pgfid10}{39622367}{38914419}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Another restriction is that those literatures mainly focus on simple model, like generalized linear models, without touching more nonlinear ones, like neural networks.}{7}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Those methods have an advantage of continuity, without a cold start once a good model has been trained. And because they have some kind of forgetting mechanism, they automatically track new concepts. However, because, each time a new data point or data batch coming in, they need to update the ensemble of models or add new models into the ensemble no matter whether concept drift happens, those methods can waste lots of computation budget. This disadvantage and the complexity of parameter tuning are probably the reason of the lack of popularity of those methods in industry.}{7}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Another type of method in the concept drift handling methods is incremental learning. One common property of incremental learning is that it usually involves only one model and the model is maintained updated to incorporate current state of concept. Such learning algorithms are usually specifically designed for a subset of models, so that the applications of them are restricted.}{7}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Both categories of methods are not designed to find the exact time when concept drift happened nor to provide diagnostic information.}{7}}
\citation{gama2004learning}
\citation{baena2006early}
\citation{ross2012exponentially}
\citation{wang2015concept}
\citation{gama2004learning}
\citation{barros2018large}
\citation{wang2015concept}
\pgfsyspdfmark {pgfid11}{13162341}{19685773}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{In\nobreakspace  {}(cite{katakis2008ensemble}), classifiers are trained using separated incoming batches of datasets. Those batches have vectors representing concepts and are accordingly clustered so that batches with a similar concept can be used to train a classifier in the ensemble. The author claimed that this method can incrementally cluster historical batches. Instead of using majority voting,\nobreakspace  {}(cite{wang2003mining}) carefully weights members in an ensemble so that those with higher validation error would receive lower weights, so that the prediction accuracy would be higher, training ensembles using batches is less computationally demanding than training a single off-line model, and the error variance is smaller. This weighting strategy can further be refined using local accuracy, which is obtained by finding k-nearest neighbors of testing data in validation datasets, as shown in\nobreakspace  {}(cite{tsymbal2008dynamic}). The accuracy is higher in this way, at the expense of more computation. One of latest reviews on ensemble learning for concept drift is\nobreakspace  {}(cite{gomes2017survey}). Those methods have an advantage of continuity, without a cold start once a good model has been trained. And because they have some kind of forgetting mechanism, they automatically track new concepts. However, because, each time a new data point or data batch coming in, they need to update the ensemble of models or add new models into the ensemble no matter whether concept drift happens, those methods can waste lots of computation budget. This disadvantage and the complexity of parameter tuning are probably the reason of the lack of popularity of those methods in industry. Another type of method in the concept drift handling methods is incremental learning. One common property of incremental learning is that it usually involves only one model and the model is maintained updated to incorporate current state of concept. Such learning algorithms are usually specifically designed for a subset of models. For example, Naive Bayes is suitable for such kind of incremental learning, because the class-conditional distributions can be easily updated by counting\nobreakspace  {}(cite{barakat2016context}, cite{katakis2006dynamic}). Two recent review papers on this topic are\nobreakspace  {}(cite{losing2018incremental}, cite{lemaire2014survey}). Both categories of methods are not designed to find the exact time when concept drift happened nor to provide diagnostic information.}{8}}
\pgfsyspdfmark {pgfid12}{2917763}{19699229}
\pgfsyspdfmark {pgfid13}{5232228}{19454043}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{and detect the time when it happens with as less delay as possible}{8}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Notice that those methods can still be applied in online updating context, but here we focus on the performance of them after models has been well-trained and validated, because this problem setting is clearer and more fundamental.}{8}}
\citation{bickel2015mathematical}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{error-based}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Monitoring the Score Function for Concept Drift}{9}{section.3}\protected@file@percent }
\pgfsyspdfmark {pgfid16}{5920357}{32995814}
\pgfsyspdfmark {pgfid19}{37307902}{33009270}
\pgfsyspdfmark {pgfid20}{39622367}{32764084}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Score Function as a Basis for Concept Drift Monitoring}{9}{subsection.3.1}\protected@file@percent }
\newlabel{ss:score_func}{{3.1}{9}{The Score Function as a Basis for Concept Drift Monitoring}{subsection.3.1}{}}
\newlabel{eqn:score_func}{{1}{9}{The Score Function as a Basis for Concept Drift Monitoring}{equation.3.1}{}}
\newlabel{eqn:score_exp_zero}{{2}{9}{The Score Function as a Basis for Concept Drift Monitoring}{equation.3.2}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{error-based}{10}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{mini-batch Gradient Descent}{10}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{Notice that the expectation in (\ref  {eqn:score_exp_zero}) is w.r.t. the conditional distribution, but the sample score vector, {$\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {x}_i, y_i))$}, has randomness from not only $P_{\bm  {\theta }} (Y|\bm  {X})$ (where $\bm  { \theta } = \bm  { \theta }^{(0)}$ when no concept drift) but also $P (\bm  {X})$. In other words, monitoring mean {drift} of {$\bm  {s} (\bm  { \theta }^{ (0)};(\bm  {x}_i, y_i))$} using control charts (which will be formally introduced later) is practically implemented by monitoring drift of {$E _{ \bm  { \theta }}[\bm  {s} (\bm  { \theta }^{ (0)};(\bm  {X}, Y))]$}. To understand the relation, using iterative expectation, we have}{10}}
\citation{bottou2018optimization}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Anh)}{According to the definition, a concept drift corresponds to change in $E _{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))| \bm  {X}]$ from $\bm  {0}$, because this indicates the change in $P(Y|\bm  {X})$. In practice, we can not directly monitor $E _{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))| \bm  {X}]$, because of lack of control in randomness from $\bm  {X}$. Instead, we actually monitor $E_{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))]$. This actually makes sense, because the {drift} of the left-hand-side in (\ref  {eqn:joint_expe}) implies the {drift} of inner expectation of the right-hand-side, meaning concept drift; the reverse is generally true except that {$E _{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))| \bm  {X}]$} has a specific form and non-zero values at different realizations of $\bm  {X}$ cancel out after taking expectation w.r.t. $\bm  {X}$. Under assumption of small changes and smooth conditions w.r.t the parameter, for generalized linear model, we can prove that concept drift in parametric models implies non-zero mean of score function. }{11}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{linear model, logistic,}{11}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{, and Poisson}{11}}
\newlabel{eqn:multi_score}{{3}{11}{The Score Function as a Basis for Concept Drift Monitoring}{equation.3.3}{}}
\@writefile{loc}{\ChangesListline {deleted}{Deleted\nobreakspace  {}(Kungang)}{all}{11}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{is}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Stochastic Gradient Descent and Sample Score Vectors}{11}{subsection.3.2}\protected@file@percent }
\newlabel{ss:sgd_score}{{3.2}{11}{Stochastic Gradient Descent and Sample Score Vectors}{subsection.3.2}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{or mini-batch Gradient Descent}{11}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{or mini-batch Gradient Descent}{11}}
\citation{ross2012exponentially}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}MEWMA Control Chart for Monitoring the Score Function}{12}{subsection.3.3}\protected@file@percent }
\newlabel{ss:MEWMA}{{3.3}{12}{MEWMA Control Chart for Monitoring the Score Function}{subsection.3.3}{}}
\newlabel{eqn:ewma}{{4}{13}{MEWMA Control Chart for Monitoring the Score Function}{equation.3.4}{}}
\newlabel{eqn:hotellingt2}{{5}{13}{MEWMA Control Chart for Monitoring the Score Function}{equation.3.5}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{After we obtaining the initial dataset, we can use MEWMA or score clustering to minimize concept drift in training data, as much as possible through retrospective analysis.}{13}}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{With}{13}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{and validated}{13}}
\citation{zeileis2007generalized}
\citation{chu1995mosum}
\citation{montgomery2007introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Comparison between Monitoring the Score Function and Other Metrics}{14}{subsection.3.4}\protected@file@percent }
\newlabel{ss:comp_other_metrics}{{3.4}{14}{Comparison between Monitoring the Score Function and Other Metrics}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Simple Logistic Regression}{15}{subsubsection.3.4.1}\protected@file@percent }
\pgfsyspdfmark {pgfid21}{5920357}{21111170}
\pgfsyspdfmark {pgfid24}{37307902}{21124626}
\pgfsyspdfmark {pgfid25}{39622367}{20879440}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{}{15}}
\newlabel{eqn:penal_err}{{6}{15}{Simple Logistic Regression}{equation.3.6}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:retro_analysis}{{1a}{16}{Retrospective Analysis.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:retro_analysis}{{a}{16}{Retrospective Analysis.\relax }{figure.caption.1}{}}
\newlabel{fig:Monitoring}{{1b}{16}{Monitoring.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:Monitoring}{{b}{16}{Monitoring.\relax }{figure.caption.1}{}}
\newlabel{fig:diagnosis}{{1c}{16}{Diagnosis.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:diagnosis}{{c}{16}{Diagnosis.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \replaced [id=Kungang, comment={}]{The framework of monitoring/detecting concept drift based on the score function. (a) Conducting retrospective analysis using MEWMA and/or score function clustering to ensure there is no concept drift in the dataset used to train and set control limits. The size of dataset can be recursively reduced if concept drift exists. (b) Monitoring concept drifts using the model and control limits obtained by processing training and Phase-I datasets. In this subplot, three examples of possible results are given: gradual and abrupt concept drift and in-control case. (c) Visualization of diagnosing concept drift: The MEWMA for score vectors and the EWMA for individual predictors are visualized to show the origin of concept drift.}{ The process of monitoring the score function using MEWMA. (a) Train a parametric model using batch or online learning method. (b) In Phase-I, make sure that the data are in-control and calculate control limits, as marked by the blue dashed-line. (c) In Phase-II, continue to monitor the new data for concept drift using the control limits calculated in Phase-I. The upper and lower figures show examples without and with concept drift.}\relax }}{16}{figure.caption.1}\protected@file@percent }
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{The framework of monitoring/detecting concept drift based on the score function. (a) Conducting retrospective analysis using MEWMA and/or score function clustering to ensure there is no concept drift in the dataset used to train and set control limits. The size of dataset can be recursively reduced if concept drift exists. (b) Monitoring concept drifts using the model and control limits obtained by processing training and Phase-I datasets. In this subplot, three examples of possible results are given: gradual and abrupt concept drift and in-control case. (c) Visualization of diagnosing concept drift: The MEWMA for score vectors and the EWMA for individual predictors are visualized to show the origin of concept drift.}{16}}
\newlabel{fig:proc_mon_score}{{1}{16}{\replaced [id=Kungang, comment={}]{The framework of monitoring/detecting concept drift based on the score function. (a) Conducting retrospective analysis using MEWMA and/or score function clustering to ensure there is no concept drift in the dataset used to train and set control limits. The size of dataset can be recursively reduced if concept drift exists. (b) Monitoring concept drifts using the model and control limits obtained by processing training and Phase-I datasets. In this subplot, three examples of possible results are given: gradual and abrupt concept drift and in-control case. (c) Visualization of diagnosing concept drift: The MEWMA for score vectors and the EWMA for individual predictors are visualized to show the origin of concept drift.}{ The process of monitoring the score function using MEWMA. (a) Train a parametric model using batch or online learning method. (b) In Phase-I, make sure that the data are in-control and calculate control limits, as marked by the blue dashed-line. (c) In Phase-II, continue to monitor the new data for concept drift using the control limits calculated in Phase-I. The upper and lower figures show examples without and with concept drift.}\relax }{figure.caption.1}{}}
\newlabel{fig:logi_err_rate_unch_a}{{2a}{17}{The Original Data generating process and model.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:logi_err_rate_unch_a}{{a}{17}{The Original Data generating process and model.\relax }{figure.caption.2}{}}
\newlabel{fig:logi_err_rate_unch_b}{{2b}{17}{The drifted data generating process.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:logi_err_rate_unch_b}{{b}{17}{The drifted data generating process.\relax }{figure.caption.2}{}}
\newlabel{fig:logi_err_rate_unch_c}{{2c}{17}{The overlap shaded area show unchanged expected error rate.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:logi_err_rate_unch_c}{{c}{17}{The overlap shaded area show unchanged expected error rate.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The demonstration of simple logistic regression that concept drift would result in no change in expected error rate.\relax }}{17}{figure.caption.2}\protected@file@percent }
\newlabel{fig:logi_err_rate_unch}{{2}{17}{The demonstration of simple logistic regression that concept drift would result in no change in expected error rate.\relax }{figure.caption.2}{}}
\newlabel{fig:logi_err_rate_penal}{{3a}{18}{The penalty function before and after concept drift by monitoring error.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:logi_err_rate_penal}{{a}{18}{The penalty function before and after concept drift by monitoring error.\relax }{figure.caption.3}{}}
\newlabel{fig:logi_score_rate_penal}{{3b}{18}{The penalty function before and after concept drift by monitoring Hotelling $T^2$ of the score function.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:logi_score_rate_penal}{{b}{18}{The penalty function before and after concept drift by monitoring Hotelling $T^2$ of the score function.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The comparison of penalty functions by monitoring classification error and Hotelling $T^2$ of EWMA of the score function.\relax }}{18}{figure.caption.3}\protected@file@percent }
\newlabel{fig:logi_med_penal}{{3}{18}{The comparison of penalty functions by monitoring classification error and Hotelling $T^2$ of EWMA of the score function.\relax }{figure.caption.3}{}}
\newlabel{eqn:penal_score}{{7}{18}{Simple Logistic Regression}{equation.3.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Other Models}{19}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The demonstration of multiple logistic regression that concept drift would result in no change in expected error rate.\relax }}{19}{figure.caption.4}\protected@file@percent }
\newlabel{fig:logi_3d}{{4}{19}{The demonstration of multiple logistic regression that concept drift would result in no change in expected error rate.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Non-Zero Mean of Score Function with Concept Drift}{19}{subsubsection.3.4.3}\protected@file@percent }
\newlabel{ss:non_zero_mean_score}{{3.4.3}{19}{Non-Zero Mean of Score Function with Concept Drift}{subsubsection.3.4.3}{}}
\pgfsyspdfmark {pgfid26}{14269758}{6095400}
\@writefile{loc}{\ChangesListline {replaced}{Replaced\nobreakspace  {}(Kungang)}{needs justification}{19}}
\pgfsyspdfmark {pgfid29}{37307902}{6108856}
\pgfsyspdfmark {pgfid30}{39622367}{5863670}
\newlabel{eqn:score_glm}{{8}{20}{Non-Zero Mean of Score Function with Concept Drift}{equation.3.8}{}}
\newlabel{eqn:exp_score_glm}{{9}{20}{Non-Zero Mean of Score Function with Concept Drift}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Monitoring Sample Score Vectors with the High-Dimension Vector of Parameters}{20}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Score function of Penalized Models}{21}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Decoupling of Concept Drift for Multivariate Regression and Classification}{22}{section.4}\protected@file@percent }
\newlabel{s:decou_cd}{{4}{22}{Score function of Penalized Models}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Concept Drift Decoupling}{22}{subsection.4.1}\protected@file@percent }
\newlabel{eqn:cd_mean_shift}{{10}{23}{Concept Drift Decoupling}{equation.4.10}{}}
\newlabel{eqn:sc_ty_expa}{{11}{23}{Concept Drift Decoupling}{equation.4.11}{}}
\newlabel{eqn:fisher_approx}{{12}{23}{Concept Drift Decoupling}{equation.4.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Variance Inflation for Covariates without Concept Drift}{23}{subsection.4.2}\protected@file@percent }
\newlabel{ss:var_infla}{{4.2}{23}{Variance Inflation for Covariates without Concept Drift}{subsection.4.2}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{Notice that the expectation in (\ref  {eqn:score_exp_zero}) is w.r.t. the conditional distribution, but the sample score vector, {$\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {x}_i, y_i))$}, has randomness from not only $P_{\bm  {\theta }} (Y|\bm  {X})$ (where $\bm  { \theta } = \bm  { \theta }^{(0)}$ when no concept drift) but also $P (\bm  {X})$. In other words, monitoring mean {drift} of {$\bm  {s} (\bm  { \theta }^{ (0)};(\bm  {x}_i, y_i))$} using control charts (which will be formally introduced later) is practically implemented by monitoring drift of {$E _{ \bm  { \theta }}[\bm  {s} (\bm  { \theta }^{ (0)};(\bm  {X}, Y))]$}. To understand the relation, using iterative expectation, we have}{24}}
\newlabel{eqn:joint_expe}{{13}{24}{Variance Inflation for Covariates without Concept Drift}{equation.4.13}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(Kungang)}{According to the definition, a concept drift corresponds to change in $E _{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))| \bm  {X}]$ from $\bm  {0}$, because this indicates the change in $P(Y|\bm  {X})$. In practice, we can not directly monitor $E _{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))| \bm  {X}]$, because of lack of control in randomness from $\bm  {X}$. Instead, we actually monitor $E_{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))]$. This actually makes sense, because the {drift} of the left-hand-side in (\ref  {eqn:joint_expe}) implies the {drift} of inner expectation of the right-hand-side, meaning concept drift; the reverse is generally true except that {$E _{ \bm  { \theta } }[\bm  {s} (\bm  { \theta } ^{ (0)};(\bm  {X}, Y))| \bm  {X}]$} has a specific form and non-zero values at different realizations of $\bm  {X}$ cancel out after taking expectation w.r.t. $\bm  {X}$. As shown in Section\nobreakspace  {}\ref  {ss:non_zero_mean_score}, under assumption of small changes and smooth conditions w.r.t the parameter, for generalized linear model, concept drift in parametric models implies non-zero mean of score function.}{24}}
\newlabel{eqn:var_aft_cd}{{14}{24}{Variance Inflation for Covariates without Concept Drift}{equation.4.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Demonstration of Monitoring the Score Function}{25}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Concept Drifts with No Error Rate Change}{25}{subsection.5.1}\protected@file@percent }
\newlabel{fig:exp_no_err_ch_a}{{5a}{26}{Concept drift results mean change in score-based method but no mean change in error rate.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:exp_no_err_ch_a}{{a}{26}{Concept drift results mean change in score-based method but no mean change in error rate.\relax }{figure.caption.5}{}}
\newlabel{fig:exp_no_err_ch_b}{{5b}{26}{After retrained on the drifted dataset, the performance of model increased, according to lower limits in prediction error.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:exp_no_err_ch_b}{{b}{26}{After retrained on the drifted dataset, the performance of model increased, according to lower limits in prediction error.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A logistic regression example with two covariates, where before blue vertical line is Phase-I and the green vertical line is the boundary between concept drift in the Phase-II. This example shows that score-based method can detect concept drift which has no change in error. This detection provides an opportunity for improvement as shown in the lower limits on the right plot.\relax }}{26}{figure.caption.5}\protected@file@percent }
\newlabel{fig:exp_no_err_ch}{{5}{26}{A logistic regression example with two covariates, where before blue vertical line is Phase-I and the green vertical line is the boundary between concept drift in the Phase-II. This example shows that score-based method can detect concept drift which has no change in error. This detection provides an opportunity for improvement as shown in the lower limits on the right plot.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Simulations on Median Run-Length ($MRL$)}{26}{subsection.5.2}\protected@file@percent }
\newlabel{ss:simu_MRL}{{5.2}{26}{Simulations on Median Run-Length ($MRL$)}{subsection.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of Phase-II MRL's of logistic regression using score and classification error, with $10000$ simulations. The ML0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1 = 0.0028369$}, {$ \lambda _2 = 0.0087330$}, {$ \lambda _3 = 0.018546$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }}{27}{table.caption.6}\protected@file@percent }
\newlabel{tab:logi_MRL}{{1}{27}{Comparison of Phase-II MRL's of logistic regression using score and classification error, with $10000$ simulations. The ML0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1 = 0.0028369$}, {$ \lambda _2 = 0.0087330$}, {$ \lambda _3 = 0.018546$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of Phase-II MRL's of multinomial regression using score and classification error, with $10000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1 = 0.0060052$}, {$ \lambda _2 = 0.010923$}, {$ \lambda _3 = 0.016641$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }}{27}{table.caption.7}\protected@file@percent }
\newlabel{tab:multi_logi_MRL}{{2}{27}{Comparison of Phase-II MRL's of multinomial regression using score and classification error, with $10000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1 = 0.0060052$}, {$ \lambda _2 = 0.010923$}, {$ \lambda _3 = 0.016641$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Concept Drift Diagnoses}{27}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Simulated Dataset for Linear Regression}{27}{subsubsection.5.3.1}\protected@file@percent }
\newlabel{sss:lin_ind_pred}{{{{(I)}}}{27}{Simulated Dataset for Linear Regression}{Item.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of Phase-II MRL's of linear regression using score and absolute residual, with $10000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ( {$ \lambda _1 = 0.0038876$}, {$ \lambda _2 = 0.028477$}, {$ \lambda _3 =0.065955$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }}{28}{table.caption.8}\protected@file@percent }
\newlabel{tab:lin_MRL}{{3}{28}{Comparison of Phase-II MRL's of linear regression using score and absolute residual, with $10000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ( {$ \lambda _1 = 0.0038876$}, {$ \lambda _2 = 0.028477$}, {$ \lambda _3 =0.065955$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Comparison of Phase-II MRL's of poisson regression using score and absolute residual, with $10000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1=0.0050701$} , {$ \lambda _2=0.0090466$}, {$ \lambda _3=0.013069$}), and $\alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }}{28}{table.caption.9}\protected@file@percent }
\newlabel{tab:pois_MRL}{{4}{28}{Comparison of Phase-II MRL's of poisson regression using score and absolute residual, with $10000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1=0.0050701$} , {$ \lambda _2=0.0090466$}, {$ \lambda _3=0.013069$}), and $\alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }{table.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparison of Phase-II MRL's of neural network ($1$ hidden layer with $10$ nodes) for logistic binary classification data using score and classification error, with $1000$ simulations. The MRL0's (in-control median) run lengths are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1=0.0010545$}, {$ \lambda _2=0.0035807$}, {$ \lambda _3=0.0082376$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }}{29}{table.caption.10}\protected@file@percent }
\newlabel{tab:logi_nnet_MRL}{{5}{29}{Comparison of Phase-II MRL's of neural network ($1$ hidden layer with $10$ nodes) for logistic binary classification data using score and classification error, with $1000$ simulations. The MRL0's (in-control median) run lengths are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1=0.0010545$}, {$ \lambda _2=0.0035807$}, {$ \lambda _3=0.0082376$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Comparison of Phase-II MRL's (median run lengths) of neural network ($1$ hidden layer with $10$ nodes) for multinomial regression data using score and classification error, with $1000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1 =0.0052546$}, {$ \lambda _2=0.0092416$}, {$ \lambda _3 =0.014028$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }}{29}{table.caption.11}\protected@file@percent }
\newlabel{tab:multi_logi_nnet_MRL}{{6}{29}{Comparison of Phase-II MRL's (median run lengths) of neural network ($1$ hidden layer with $10$ nodes) for multinomial regression data using score and classification error, with $1000$ simulations. The MRL0's (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1 =0.0052546$}, {$ \lambda _2=0.0092416$}, {$ \lambda _3 =0.014028$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }{table.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Abrupt concept drift of linear model with independent covariates (colorful in electronic version). For conciseness, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), intercept (green), and Hotelling $T^2$ (black). The blue and green vertical lines mark the boundaries of Phase-I/II and before/after concept drift. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{30}{figure.caption.13}\protected@file@percent }
\newlabel{fig:lin_reg_ind_X}{{6}{30}{Abrupt concept drift of linear model with independent covariates (colorful in electronic version). For conciseness, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), intercept (green), and Hotelling $T^2$ (black). The blue and green vertical lines mark the boundaries of Phase-I/II and before/after concept drift. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Abrupt concept drift of linear model with independent covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{30}{figure.caption.14}\protected@file@percent }
\newlabel{fig:lin_reg_ind_X_comp}{{7}{30}{Abrupt concept drift of linear model with independent covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Comparison of Phase-II MRL's (median run lengths) of neural network ($1$ hidden layer with $10$ nodes) for linear regression data using score and absolute residual, with $1000$ simulations. The MRL0' (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1=0.0021882$}, {$ \lambda _2=0.012062$}, {$ \lambda _3=0.027374$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }}{31}{table.caption.12}\protected@file@percent }
\newlabel{tab:lin_nnet_MRL}{{7}{31}{Comparison of Phase-II MRL's (median run lengths) of neural network ($1$ hidden layer with $10$ nodes) for linear regression data using score and absolute residual, with $1000$ simulations. The MRL0' (in-control median run lengths) are matched as close as possible. $ \lambda $ is the EWMA parameter ({$ \lambda _1=0.0021882$}, {$ \lambda _2=0.012062$}, {$ \lambda _3=0.027374$}), and $ \alpha $ is the change factor ($ \alpha =0$ corresponds to in-control case).\relax }{table.caption.12}{}}
\newlabel{sss:lin_not_ind_pred}{{{{(II)}}}{32}{Simulated Dataset for Linear Regression}{Item.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Abrupt concept drift of linear model with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{32}{figure.caption.15}\protected@file@percent }
\newlabel{fig:lin_reg_not_ind_X}{{8}{32}{Abrupt concept drift of linear model with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf {I} ( {\bm {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.15}{}}
\newlabel{sss:lin_not_ind_pred_grad_cd}{{{{(III)}}}{32}{Simulated Dataset for Linear Regression}{Item.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Gradual concept drift of linear model with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The left (right) vertical axis is for univariate (multivariate) control charts. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{33}{figure.caption.16}\protected@file@percent }
\newlabel{fig:lin_reg_not_ind_X_grad_cd}{{9}{33}{Gradual concept drift of linear model with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf {I} ( {\bm {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The left (right) vertical axis is for univariate (multivariate) control charts. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Gradual concept drift of linear model with correlated covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{33}{figure.caption.17}\protected@file@percent }
\newlabel{fig:lin_reg_ind_X_grad_cd_comp}{{10}{33}{Gradual concept drift of linear model with correlated covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Simulated Dataset for Logistic Regression}{34}{subsubsection.5.3.2}\protected@file@percent }
\newlabel{sss:log_ind_pred}{{{{(I)}}}{34}{Simulated Dataset for Logistic Regression}{Item.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Abrupt concept drift of logistic regression with independent {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{34}{figure.caption.18}\protected@file@percent }
\newlabel{fig:log_reg_ind_X}{{11}{34}{Abrupt concept drift of logistic regression with independent {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf {I} ( {\bm {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Abrupt concept drift of logistic regression with independent covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the error rate are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{35}{figure.caption.19}\protected@file@percent }
\newlabel{fig:log_reg_ind_X_comp}{{12}{35}{Abrupt concept drift of logistic regression with independent covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the error rate are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.19}{}}
\newlabel{sss:log_not_ind_pred}{{{{(II)}}}{35}{Simulated Dataset for Logistic Regression}{Item.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces  Abrupt concept drift of logistic regression with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }}{36}{figure.caption.20}\protected@file@percent }
\newlabel{fig:log_reg_not_ind_X}{{13}{36}{Abrupt concept drift of logistic regression with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf {I} ( {\bm {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }{figure.caption.20}{}}
\newlabel{sss:log_not_ind_pred_assum}{{{{(III)}}}{36}{Simulated Dataset for Logistic Regression}{Item.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces  Abrupt concept drift of logistic regression with correlated covariates (colorful in electronic version). Simulated data are modified to reduce the magnitude of $ \bm  {x}_i^T\bm  { \theta }^{(1)}$ and $ \bm  {x}_i^T\bm  { \theta }^{(0)}$. Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }}{37}{figure.caption.21}\protected@file@percent }
\newlabel{fig:log_reg_not_ind_X_1}{{14}{37}{Abrupt concept drift of logistic regression with correlated covariates (colorful in electronic version). Simulated data are modified to reduce the magnitude of $ \bm {x}_i^T\bm { \theta }^{(1)}$ and $ \bm {x}_i^T\bm { \theta }^{(0)}$. Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf {I} ( {\bm {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Gradual concept drift of logistic regression with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The left (right) vertical axis is for univariate (multivariate) control charts. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{38}{figure.caption.22}\protected@file@percent }
\newlabel{fig:log_reg_not_ind_X_grad_cd}{{15}{38}{Gradual concept drift of logistic regression with correlated {covariates} (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by {the inverse of the estimated} Fisher Information Matrix, {$\mathbf {I} ( {\bm {\theta }} ^{(0)})$.} For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $5$th (red), $7$th (green), intercept (cyan), and Hotelling $T^2$ (black). The left (right) vertical axis is for univariate (multivariate) control charts. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Gradual concept drift of logistic regression with correlated covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }}{38}{figure.caption.23}\protected@file@percent }
\newlabel{fig:log_reg_ind_X_grad_cd_comp}{{16}{38}{Gradual concept drift of logistic regression with correlated covariates (colorful in electronic version). Control charts of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared. The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly.\relax }{figure.caption.23}{}}
\citation{im2012time}
\@writefile{toc}{\contentsline {section}{\numberline {6}Real Datasets}{39}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Credit Risk Dataset}{39}{subsection.6.1}\protected@file@percent }
\newlabel{ss:cr_ds}{{6.1}{39}{Credit Risk Dataset}{subsection.6.1}{}}
\citation{barros2018large}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces  Control charts monitoring MEWMA of Hotelling $T^2$ of the score function and EWMA of the prediction error are compared using credit risk dataset. The left plots are from logistic regression, and the right from MLP with one hidden layer of $50$ nodes. The tilted numbers along the x-axis, as the indices of month, are the time of credit card defaults. For example, $601$ stands for 2006-Jan. So the index $712$ is for the 2007-Dec, right after which a $15$-month significant drop began (S\&P 500 from $1478.49$ on 2007-Dec.28 to $683.38$ on 2009-Mar.28). \relax }}{40}{figure.caption.24}\protected@file@percent }
\newlabel{fig:credit_default}{{17}{40}{Control charts monitoring MEWMA of Hotelling $T^2$ of the score function and EWMA of the prediction error are compared using credit risk dataset. The left plots are from logistic regression, and the right from MLP with one hidden layer of $50$ nodes. The tilted numbers along the x-axis, as the indices of month, are the time of credit card defaults. For example, $601$ stands for 2006-Jan. So the index $712$ is for the 2007-Dec, right after which a $15$-month significant drop began (S\&P 500 from $1478.49$ on 2007-Dec.28 to $683.38$ on 2009-Mar.28). \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces  MEWMA and EWMA control charts for logistic regression of credit risk dataset (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $2$nd (red), $3$rd (green), $8$th (cyan), intercept (orange), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }}{41}{figure.caption.25}\protected@file@percent }
\newlabel{fig:credit_default_diag}{{18}{41}{MEWMA and EWMA control charts for logistic regression of credit risk dataset (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf {I} ( {\bm {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the $1$st (blue), $2$nd (red), $3$rd (green), $8$th (cyan), intercept (orange), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Bike Sharing Dataset}{42}{subsection.6.2}\protected@file@percent }
\newlabel{ss:bs_ds}{{6.2}{42}{Bike Sharing Dataset}{subsection.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces  Control charts monitoring MEWMA of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared using bike sharing dataset. The left plots are from linear regression, and the right from MLP with one hidden layer of $50$ nodes. The tilted numbers along the x-axis, as the indices of year, are the time of bike sharing data collected. \relax }}{42}{figure.caption.26}\protected@file@percent }
\newlabel{fig:bike_sharing}{{19}{42}{Control charts monitoring MEWMA of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared using bike sharing dataset. The left plots are from linear regression, and the right from MLP with one hidden layer of $50$ nodes. The tilted numbers along the x-axis, as the indices of year, are the time of bike sharing data collected. \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces  MEWMA and EWMA control charts for linear regression of bike sharing dataset (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the temperature (blue), windspeed (red), humidity (green), label of $9$am of days (cyan), intercept (orange), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }}{43}{figure.caption.27}\protected@file@percent }
\newlabel{fig:bike_sharing_diag}{{20}{43}{MEWMA and EWMA control charts for linear regression of bike sharing dataset (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf {I} ( {\bm {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the temperature (blue), windspeed (red), humidity (green), label of $9$am of days (cyan), intercept (orange), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces  Control charts monitoring MEWMA of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared using bike sharing dataset with responses dividing by yearly moving average. The left two plots are from linear regression, and the right from MLP with one hidden layer of $50$ nodes. The tilted numbers along the x-axis, as the indices of year, are the time of bike sharing data collected. \relax }}{44}{figure.caption.28}\protected@file@percent }
\newlabel{fig:bike_sharing_preproc}{{21}{44}{Control charts monitoring MEWMA of Hotelling $T^2$ of the score function and EWMA of the absolute residual are compared using bike sharing dataset with responses dividing by yearly moving average. The left two plots are from linear regression, and the right from MLP with one hidden layer of $50$ nodes. The tilted numbers along the x-axis, as the indices of year, are the time of bike sharing data collected. \relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces  MEWMA and EWMA control charts for linear regression of bike sharing dataset with responses dividing by yearly moving average (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf  {I} ( {\bm  {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the temperature (blue), windspeed (red), humidity (green), label of $9$am of days (cyan), intercept (orange), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }}{45}{figure.caption.29}\protected@file@percent }
\newlabel{fig:bike_sharing_preproc_diag}{{22}{45}{MEWMA and EWMA control charts for linear regression of bike sharing dataset with responses dividing by yearly moving average (colorful in electronic version). Comparison are made between before (left) and after (right) being scaled by the inverse of the estimated Fisher Information Matrix, $\mathbf {I} ( {\bm {\theta }} ^{(0)})$. For legibility, here only show EWMA (or MEWMA) control charts for the temperature (blue), windspeed (red), humidity (green), label of $9$am of days (cyan), intercept (orange), and Hotelling $T^2$ (black). The lines of monitored statistics in control charts have the same style and color with lines of their control limits correspondingly. \relax }{figure.caption.29}{}}
\bibdata{sample}
\bibcite{baena2006early}{{1}{2006}{{Baena-Garc{\i }a et~al.}}{{Baena-Garc{\i }a, del Campo-{\'A}vila, Fidalgo, Bifet, Gavalda, and Morales-Bueno}}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Training and testing $R^2$ with or without normalizing responses by yearly moving average.\relax }}{46}{table.caption.30}\protected@file@percent }
\newlabel{table:fit_pred_preproc}{{8}{46}{Training and testing $R^2$ with or without normalizing responses by yearly moving average.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{46}{section.7}\protected@file@percent }
\bibcite{barakat2016context}{{2}{2016}{{Barakat}}{{}}}
\bibcite{barakat2018context}{{3}{2018}{{Barakat et~al.}}{{Barakat, Pavlidis, and Crone}}}
\bibcite{barros2018large}{{4}{2018}{{Barros and Santos}}{{}}}
\bibcite{bickel2015mathematical}{{5}{2015}{{Bickel and Doksum}}{{}}}
\bibcite{bottou2018optimization}{{6}{2018}{{Bottou et~al.}}{{Bottou, Curtis, and Nocedal}}}
\bibcite{bui2018monitoring}{{7}{2018}{{Bui and Apley}}{{}}}
\bibcite{calandra2012learning}{{8}{2012}{{Calandra et~al.}}{{Calandra, Raiko, Deisenroth, and Pouzols}}}
\bibcite{carmona2010gnusmail}{{9}{2010}{{Carmona-Cejudo et~al.}}{{Carmona-Cejudo, Baena-Garc{\'i}a, del Campo-{\'A}vila, Morales-Bueno, and Bifet}}}
\bibcite{chu1995mosum}{{10}{1995}{{Chu et~al.}}{{Chu, Hornik, and Kaun}}}
\bibcite{dos2016fast}{{11}{2016}{{dos Reis et~al.}}{{dos Reis, Flach, Matwin, and Batista}}}
\bibcite{fong2015change}{{12}{2015}{{Fong et~al.}}{{Fong, Di, and Permar}}}
\bibcite{frias2015online}{{13}{2015}{{Fr{\'\i }as-Blanco et~al.}}{{Fr{\'\i }as-Blanco, del Campo-{\'A}vila, Ramos-Jim{\'e}nez, Morales-Bueno, Ortiz-D{\'\i }az, and Caballero-Mota}}}
\bibcite{gama2004learning}{{14}{2004}{{Gama et~al.}}{{Gama, Medas, Castillo, and Rodrigues}}}
\bibcite{gomes2017survey}{{15}{2017}{{Gomes et~al.}}{{Gomes, Barddal, Enembreck, and Bifet}}}
\bibcite{gonccalves2014comparative}{{16}{2014}{{Gon{\c {c}}alves~Jr et~al.}}{{Gon{\c {c}}alves~Jr, de~Carvalho~Santos, Barros, and Vieira}}}
\bibcite{im2012time}{{17}{2012}{{Im et~al.}}{{Im, Apley, Qi, and Shan}}}
\bibcite{katakis2006dynamic}{{18}{2006}{{Katakis et~al.}}{{Katakis, Tsoumakas, and Vlahavas}}}
\bibcite{katakis2008ensemble}{{19}{2008}{{Katakis et~al.}}{{Katakis, Tsoumakas, and Vlahavas}}}
\bibcite{koren2009collaborative}{{20}{2009}{{Koren}}{{}}}
\bibcite{lemaire2014survey}{{21}{2014}{{Lemaire et~al.}}{{Lemaire, Salperwyck, and Bondu}}}
\bibcite{losing2018incremental}{{22}{2018}{{Losing et~al.}}{{Losing, Hammer, and Wersing}}}
\bibcite{montgomery2007introduction}{{23}{2007}{{Montgomery}}{{}}}
\bibcite{moreno2012unifying}{{24}{2012}{{Moreno-Torres et~al.}}{{Moreno-Torres, Raeder, Alaiz-Rodr{\'\i }Guez, Chawla, and Herrera}}}
\bibcite{ross2012exponentially}{{25}{2012}{{Ross et~al.}}{{Ross, Adams, Tasoulis, and Hand}}}
\bibcite{tsymbal2004problem}{{26}{2004}{{Tsymbal}}{{}}}
\bibcite{tsymbal2008dynamic}{{27}{2008}{{Tsymbal et~al.}}{{Tsymbal, Pechenizkiy, Cunningham, and Puuronen}}}
\bibcite{wang2003mining}{{28}{2003}{{Wang et~al.}}{{Wang, Fan, Yu, and Han}}}
\bibcite{wang2015concept}{{29}{2015}{{Wang and Abraham}}{{}}}
\bibcite{xia2009monitoring}{{30}{2009}{{Xia et~al.}}{{Xia, Guo, and Zhao}}}
\bibcite{zeileis2005unified}{{31}{2005}{{Zeileis}}{{}}}
\bibcite{zeileis2007generalized}{{32}{2007}{{Zeileis and Hornik}}{{}}}
\bibcite{vzliobaite2016overview}{{33}{2016}{{{\v {Z}}liobait{\.e} et~al.}}{{{\v {Z}}liobait{\.e}, Pechenizkiy, and Gama}}}
\newlabel{app:sgd_ewma}{{7}{49}{Bike Sharing Dataset}{section*.31}{}}
\citation{bottou2018optimization}
\newlabel{eqn:ewma_expa}{{15}{50}{Bike Sharing Dataset}{equation.0.15}{}}
\newlabel{eqn:exp_ewma_expa}{{16}{50}{Bike Sharing Dataset}{equation.0.16}{}}
